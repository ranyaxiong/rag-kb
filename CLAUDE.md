# RAG Knowledge Base - Claude Code Development Guide

This comprehensive guide provides everything a Claude Code instance needs to understand and work productively with the RAG Knowledge Base codebase.

## ğŸ—ï¸ System Architecture

### Overview
A production-ready RAG (Retrieval-Augmented Generation) knowledge base application with FastAPI backend, Streamlit frontend, and multi-provider LLM support.

### Core Components
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI   â”‚    â”‚   FastAPI API   â”‚    â”‚  Document Proc  â”‚
â”‚  (Frontend)     â”‚ â†â†’ â”‚   (Backend)     â”‚ â†â†’ â”‚   (Core Logic)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChromaDB      â”‚    â”‚   Vector Store  â”‚    â”‚   QA Engine     â”‚
â”‚   (Vector DB)   â”‚ â†â†’ â”‚   (Manager)     â”‚ â†â†’ â”‚   (RAG Logic)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Provider LLM Support                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   OpenAI     â”‚ â”‚   DeepSeek    â”‚ â”‚   Zhipu AI   â”‚            â”‚
â”‚  â”‚ GPT-3.5/4    â”‚ â”‚ deepseek-chat â”‚ â”‚   GLM-4      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure
```
rag_kb/
â”œâ”€â”€ app/                      # Backend application
â”‚   â”œâ”€â”€ api/                  # API endpoints
â”‚   â”‚   â”œâ”€â”€ documents.py      # Document management API
â”‚   â”‚   â””â”€â”€ qa.py            # Question-answering API
â”‚   â”œâ”€â”€ core/                 # Core business logic
â”‚   â”‚   â”œâ”€â”€ config.py         # Multi-provider configuration
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document parsing & chunking
â”‚   â”‚   â”œâ”€â”€ qa_engine.py      # RAG question-answering engine
â”‚   â”‚   â””â”€â”€ vector_store.py   # Vector database management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic data models
â”‚   â””â”€â”€ main.py              # FastAPI application entry
â”œâ”€â”€ frontend/                 # Streamlit frontend
â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â””â”€â”€ streamlit_app.py     # Main frontend app
â”œâ”€â”€ docker/                   # Container configurations
â”‚   â”œâ”€â”€ Dockerfile.backend    # Backend container
â”‚   â”œâ”€â”€ Dockerfile.frontend   # Frontend container
â”‚   â”œâ”€â”€ docker-compose.yml    # Production setup
â”‚   â””â”€â”€ docker-compose.dev.yml # Development setup
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ uploads/             # Uploaded documents (date-organized)
â”‚   â””â”€â”€ chroma_db/           # ChromaDB vector storage
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ scripts/                  # Automation scripts
â””â”€â”€ secrets/                  # Secure credential storage
```

## ğŸš€ Quick Start Commands

### Development Setup
```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows

# 2. Install dependencies
make install
# or: pip install -r requirements.txt

# 3. Configure API keys (see Multi-Provider Setup below)
make setup-keyring  # Recommended secure method
# or: cp .env.deepseek .env && edit API key

# 4. Start development mode (both backend + frontend)
make dev
# Backend: http://localhost:8000
# Frontend: http://localhost:8501
# API Docs: http://localhost:8000/docs
```

### Docker Development
```bash
# Development mode with hot reload
make docker-dev
# or: cd docker && docker-compose -f docker-compose.dev.yml up -d

# Production mode
make docker-run
# or: cd docker && docker-compose up -d

# View logs
make docker-logs
# Stop services
make docker-stop
```

### Testing
```bash
# Run all tests with coverage
make test
# or: pytest tests/ -v --cov=app --cov-report=html

# Run specific test file
pytest tests/test_api.py -v

# Generate HTML coverage report
make test-html
```

### Code Quality
```bash
# Format code
make format
# or: black app/ tests/ frontend/ && isort app/ tests/ frontend/

# Lint code
make lint
# or: flake8 app/ tests/ --max-line-length=88

# Clean cache files
make clean
```

## ğŸ”§ Multi-Provider LLM Configuration

### Supported Providers
- **OpenAI**: GPT-3.5/4, text-embedding-ada-002
- **DeepSeek**: deepseek-chat, compatible with OpenAI embeddings
- **Zhipu AI (GLM)**: glm-4, embedding-2

### Quick Configuration
```bash
# DeepSeek (recommended - large free tier)
cp .env.deepseek .env
# Edit API_KEY=sk-your-deepseek-key-here

# Zhipu AI
cp .env.zhipu .env
# Edit API_KEY=your-zhipu-key-here

# OpenAI
export OPENAI_API_KEY="sk-your-openai-key-here"
```

### Secure Configuration (Recommended)
```bash
# Use system keyring (most secure)
make setup-keyring
# Follow prompts to store API key securely

# Verify configuration
make check-security
```

### Configuration Architecture
The `app/core/config.py` provides sophisticated multi-provider support:

```python
# Key configuration options
LLM_PROVIDER = "deepseek"  # or "openai", "zhipu"
EMBEDDING_PROVIDER = "openai"  # can differ from LLM provider
API_KEY = "your-api-key"  # or use secure methods
CHAT_MODEL = "deepseek-chat"  # auto-configured per provider
EMBEDDING_MODEL = "text-embedding-ada-002"
```

Multiple secure API key sources (in priority order):
1. Environment variables (`API_KEY`)
2. Secure files (`API_KEY_FILE`)
3. Base64 encoded (`API_KEY_BASE64`)
4. Docker secrets (`/run/secrets/`)
5. System keyring (Linux/Mac)
6. Backward compatibility with OpenAI-specific vars

## ğŸ  Development Environment

### Local Development
```bash
# Terminal 1: Backend with auto-reload
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Frontend with auto-reload
BACKEND_URL=http://localhost:8000 streamlit run frontend/streamlit_app.py

# Or use make command (runs both)
make dev
```

### Docker Development (Hot Reload)
```bash
# Start with source code mounting for hot reload
cd docker
docker-compose -f docker-compose.dev.yml up -d

# View real-time logs
docker-compose -f docker-compose.dev.yml logs -f
```

### Health Checks
```bash
# Check all services
make health

# Manual checks
curl http://localhost:8000/health      # Backend health
curl http://localhost:8000/info        # System info
curl http://localhost:8501             # Frontend check
```

## ğŸ“„ Document Processing Pipeline

### Supported Formats
- **PDF**: PyPDFLoader
- **Word**: UnstructuredWordDocumentLoader (.docx, .doc)
- **Text**: TextLoader (.txt)
- **Markdown**: UnstructuredMarkdownLoader (.md)

### Processing Flow
1. **Upload** â†’ File saved with UUID prefix in date-organized folders
2. **Parse** â†’ Format-specific content extraction
3. **Chunk** â†’ RecursiveCharacterTextSplitter (size: 1000, overlap: 200)
4. **Embed** â†’ OpenAI/compatible embedding generation
5. **Store** â†’ ChromaDB vector storage with metadata
6. **Index** â†’ Available for RAG retrieval

### Key Classes
```python
# Document processing
from app.core.document_processor import DocumentProcessor
processor = DocumentProcessor()
result = processor.process_document(file_path, filename)

# Vector storage management
from app.core.vector_store import VectorStore
vector_store = VectorStore()  # Singleton pattern
doc_ids = vector_store.add_documents(chunks)

# RAG question answering
from app.core.qa_engine import QAEngine
qa_engine = QAEngine(vector_store)
response = qa_engine.ask(question)
```

## ğŸ¤– RAG Question-Answering System

### QA Engine Architecture
- **Retriever**: ChromaDB similarity search (configurable k sources)
- **LLM**: Multi-provider chat models with custom prompts
- **Chain**: LangChain RetrievalQA with "stuff" strategy
- **Response**: Structured answer with source documents and timing

### Key Configuration
```python
# In app/core/config.py
MAX_SOURCES = 3              # Sources per query
SIMILARITY_THRESHOLD = 0.7   # Vector similarity threshold
CHUNK_SIZE = 1000           # Document chunk size
CHUNK_OVERLAP = 200         # Overlap between chunks
```

### Custom Prompt Template
The system uses a carefully crafted prompt template that:
- Encourages document-based answers
- Handles cases where information isn't available
- Requests structured, helpful responses
- Supports multi-point explanations

### Usage Examples
```python
# Basic question answering
response = qa_engine.ask("What is the main topic of the documents?")
print(response.answer)
print(f"Processing time: {response.processing_time}s")
for source in response.sources:
    print(f"Source: {source.document_name}")
    print(f"Content: {source.content}")

# Document retrieval only (no LLM generation)
docs = qa_engine.get_relevant_documents("search query", k=5)
```

## ğŸ§ª Testing Framework

### Test Structure
```bash
tests/
â”œâ”€â”€ conftest.py           # Pytest configuration and fixtures
â”œâ”€â”€ test_api.py          # API endpoint tests
â””â”€â”€ test_document_processor.py  # Core logic tests
```

### Key Testing Patterns
```python
# Mock settings for consistent testing
@pytest.fixture
def mock_settings():
    with patch('app.core.config.settings') as mock:
        mock.openai_api_key = "test-key"
        mock.upload_dir = "/tmp/test_uploads"
        # ... other test configurations
        yield mock

# API testing with FastAPI TestClient
from fastapi.testclient import TestClient
from app.main import app
client = TestClient(app)

def test_health_endpoint():
    response = client.get("/health")
    assert response.status_code == 200
```

### Coverage Requirements
- Minimum coverage: 70% (configured in pytest.ini)
- HTML reports generated in `htmlcov/`
- Focus on core business logic and API endpoints

## ğŸ³ Docker & Deployment

### Container Architecture
- **Backend**: Python 3.11 slim with FastAPI + dependencies
- **Frontend**: Streamlit with backend connectivity
- **Development**: Volume mounts for hot reload
- **Production**: Optimized images with health checks

### Environment Configurations

**Development** (docker-compose.dev.yml):
- Source code volume mounting
- Hot reload enabled
- Debug logging
- Simplified networking

**Production** (docker-compose.yml):
- Optimized images
- Health checks enabled
- Restart policies
- Environment variable management

### Deployment Commands
```bash
# Development deployment
make docker-dev

# Production deployment
make docker-run

# Check service status
make docker-ps

# View logs
make docker-logs

# Scale services (if needed)
docker-compose up -d --scale backend=2
```

## ğŸ” Security Best Practices

### API Key Management
The system implements multiple secure API key storage methods:

1. **System Environment Variables** (Recommended)
2. **System Keyring** (Most Secure)
3. **Docker Secrets** (Production)
4. **Encrypted Files** (Limited use)

### Security Checklist
- âœ… Never commit API keys to Git
- âœ… Use `.gitignore` for sensitive files
- âœ… Implement secure key rotation
- âœ… Monitor API usage and costs
- âœ… Use HTTPS in production
- âœ… Enable CORS appropriately
- âœ… Validate file uploads (size, type)

### Emergency Procedures
If API keys are compromised:
1. Immediately revoke compromised keys
2. Generate new keys
3. Update all services using secure methods
4. Review logs for unauthorized usage
5. Document incident and improve procedures

## ğŸ“Š Monitoring & Debugging

### Health Check Endpoints
```bash
# Backend system health
GET /health
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00",
  "version": "1.0.0"
}

# QA system health
GET /api/qa/health
{
  "success": true,
  "health": {
    "status": "healthy",
    "llm": "connected",
    "vector_store": "healthy",
    "qa_chain": "working"
  }
}

# System information
GET /info
```

### Logging Strategy
- **Structured Logging**: JSON format for production
- **Log Levels**: INFO for normal operations, DEBUG for development
- **Log Files**: Stored in `logs/` directory
- **Rotation**: Automatic log rotation in production

### Common Issues & Solutions

**Issue**: API key not found
```bash
# Check configuration
python -c "from app.core.config import settings; print(bool(settings.get_api_key()))"

# Verify environment
make check-security
```

**Issue**: Document processing fails
```bash
# Check supported formats
curl http://localhost:8000/api/documents/stats/overview

# Verify file permissions
ls -la data/uploads/
```

**Issue**: Vector search returns no results
```bash
# Check collection info
curl http://localhost:8000/api/qa/stats

# Verify documents are indexed
curl http://localhost:8000/api/documents/
```

## ğŸ”„ CI/CD Pipeline

### GitHub Actions Integration
The repository includes CI/CD workflows for:
- **Testing**: Automated test execution on PR/push
- **Linting**: Code quality checks
- **Docker**: Container image building
- **Deployment**: Production deployment automation

### Local CI Testing
```bash
# Run full build process
make build

# This executes:
# 1. Clean cache and temp files
# 2. Install fresh dependencies
# 3. Run complete test suite
# 4. Verify all tests pass
```

## ğŸ¯ Common Development Tasks

### Adding New Document Formats
1. Extend `loaders` dict in `DocumentProcessor`
2. Add format-specific dependencies to `requirements.txt`
3. Update tests and documentation

### Implementing New LLM Providers
1. Add provider configuration to `Settings.get_model_config()`
2. Update provider-specific API endpoints
3. Test compatibility with existing RAG pipeline

### Frontend Customization
1. Modify Streamlit components in `frontend/components/`
2. Update main interface in `streamlit_app.py`
3. Test responsive behavior and error handling

### Performance Optimization
1. Adjust chunk sizes in configuration
2. Implement caching for frequent queries
3. Optimize vector search parameters
4. Monitor LLM token usage

## ğŸ“‹ Development Checklist

When working on this codebase:

### Before Starting
- [ ] Verify API keys are configured securely
- [ ] Confirm backend and frontend services start successfully
- [ ] Run health checks to ensure system readiness
- [ ] Review recent commits for context

### During Development
- [ ] Use appropriate testing with `make test`
- [ ] Follow code formatting with `make format`
- [ ] Check linting with `make lint`
- [ ] Test both local and Docker environments

### Before Committing
- [ ] Ensure all tests pass
- [ ] Verify code formatting is consistent
- [ ] Check that no secrets are being committed
- [ ] Update documentation if needed
- [ ] Test end-to-end functionality

### Production Deployment
- [ ] Use production Docker configuration
- [ ] Enable proper monitoring and logging
- [ ] Verify security configurations
- [ ] Test with representative data load
- [ ] Plan rollback procedures

## ğŸ¤ Architecture Principles

This codebase follows several key architectural principles:

### Separation of Concerns
- **API Layer**: Clean REST endpoints with proper validation
- **Business Logic**: Core RAG functionality isolated in `core/` modules
- **Data Layer**: Abstracted database interactions
- **Presentation**: Streamlit UI components separate from logic

### Configuration Management
- **Environment-based**: Different configs for dev/prod
- **Secure by Default**: Multiple secure API key storage options
- **Provider-agnostic**: Easy switching between LLM providers

### Scalability Considerations
- **Singleton Pattern**: Efficient resource management for vector store
- **Async Processing**: Background document processing
- **Containerization**: Easy horizontal scaling with Docker
- **Stateless Design**: Services can be replicated as needed

### Error Handling
- **Graceful Degradation**: System continues operating with partial failures
- **Informative Messages**: User-friendly error communication
- **Comprehensive Logging**: Detailed error tracking for debugging

This guide should provide everything needed for a Claude Code instance to quickly understand and productively work with this RAG knowledge base codebase. The system is well-architected with clear separation of concerns, comprehensive configuration options, and robust development practices.